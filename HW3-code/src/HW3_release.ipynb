{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7H420KxmCjKH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BCDUFCh7Fd-n"
   },
   "outputs": [],
   "source": [
    "# To add your own Drive Run this cell.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nQXiXrbaF3NK"
   },
   "outputs": [],
   "source": [
    "# Please append your own directory after â€˜/content/drive/My Drive/'\n",
    "### ========== TODO : START ========== ###\n",
    "sys.path += ['/content/drive/My Drive/cm146-spring23/hw3/HW3-code']\n",
    "### ========== TODO : END ========== ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7_OLupUPC2U3"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author      : Yi-Chieh Wu, Sriram Sankararman\n",
    "Description : Twitter\n",
    "\"\"\"\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# !!! MAKE SURE TO USE LinearSVC.decision_function(X), NOT LinearSVC.predict(X) !!!\n",
    "# (this makes ''continuous-valued'' predictions)\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47L2XVzBX6c5"
   },
   "source": [
    "# Problem 3: Twitter Analysis Using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "9Z8E5YL0CzWe"
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# functions -- input/output\n",
    "######################################################################\n",
    "\n",
    "def read_vector_file(fname):\n",
    "    \"\"\"\n",
    "    Reads and returns a vector from a file.\n",
    "\n",
    "    Parameters\n",
    "    --------------------\n",
    "        fname  -- string, filename\n",
    "\n",
    "    Returns\n",
    "    --------------------\n",
    "        labels -- numpy array of shape (n,)\n",
    "                    n is the number of non-blank lines in the text file\n",
    "    \"\"\"\n",
    "    return np.genfromtxt(fname)\n",
    "\n",
    "\n",
    "def write_label_answer(vec, outfile):\n",
    "    \"\"\"\n",
    "    Writes your label vector to the given file.\n",
    "\n",
    "    Parameters\n",
    "    --------------------\n",
    "        vec     -- numpy array of shape (n,) or (n,1), predicted scores\n",
    "        outfile -- string, output filename\n",
    "    \"\"\"\n",
    "\n",
    "    # for this project, you should predict 70 labels\n",
    "    if(vec.shape[0] != 70):\n",
    "        print(\"Error - output vector should have 70 rows.\")\n",
    "        print(\"Aborting write.\")\n",
    "        return\n",
    "\n",
    "    np.savetxt(outfile, vec)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "i67aTAmrGGHi"
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# functions -- feature extraction\n",
    "######################################################################\n",
    "\n",
    "def extract_words(input_string):\n",
    "    \"\"\"\n",
    "    Processes the input_string, separating it into \"words\" based on the presence\n",
    "    of spaces, and separating punctuation marks into their own words.\n",
    "\n",
    "    Parameters\n",
    "    --------------------\n",
    "        input_string -- string of characters\n",
    "\n",
    "    Returns\n",
    "    --------------------\n",
    "        words        -- list of lowercase \"words\"\n",
    "    \"\"\"\n",
    "\n",
    "    for c in punctuation :\n",
    "        input_string = input_string.replace(c, ' ' + c + ' ')\n",
    "    return input_string.lower().split()\n",
    "\n",
    "\n",
    "def extract_dictionary(infile):\n",
    "    \"\"\"\n",
    "    Given a filename, reads the text file and builds a dictionary of unique\n",
    "    words/punctuations.\n",
    "\n",
    "    Parameters\n",
    "    --------------------\n",
    "        infile    -- string, filename\n",
    "\n",
    "    Returns\n",
    "    --------------------\n",
    "        word_list -- dictionary, (key, value) pairs are (word, index)\n",
    "    \"\"\"\n",
    "\n",
    "    word_list = {}\n",
    "    idx = 0\n",
    "    with open(infile, 'r') as fid :\n",
    "        # process each line to populate word_list\n",
    "        for input_string in fid:\n",
    "            words = extract_words(input_string)\n",
    "            for word in words:\n",
    "                if word not in word_list:\n",
    "                    word_list[word] = idx\n",
    "                    idx += 1\n",
    "    return word_list\n",
    "\n",
    "\n",
    "def extract_feature_vectors(infile, word_list):\n",
    "    \"\"\"\n",
    "    Produces a bag-of-words representation of a text file specified by the\n",
    "    filename infile based on the dictionary word_list.\n",
    "\n",
    "    Parameters\n",
    "    --------------------\n",
    "        infile         -- string, filename\n",
    "        word_list      -- dictionary, (key, value) pairs are (word, index)\n",
    "\n",
    "    Returns\n",
    "    --------------------\n",
    "        feature_matrix -- numpy array of shape (n,d)\n",
    "                          boolean (0,1) array indicating word presence in a string\n",
    "                            n is the number of non-blank lines in the text file\n",
    "                            d is the number of unique words in the text file\n",
    "    \"\"\"\n",
    "\n",
    "    num_lines = sum(1 for line in open(infile,'r'))\n",
    "    num_words = len(word_list)\n",
    "    feature_matrix = np.zeros((num_lines, num_words))\n",
    "\n",
    "    with open(infile, 'r') as fid :\n",
    "        # process each line to populate feature_matrix\n",
    "        for i, input_string in enumerate(fid):\n",
    "            words = extract_words(input_string)\n",
    "            for word in words:\n",
    "                feature_matrix[i, word_list[word]] = 1.0\n",
    "\n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "-MvTxQPRGOOf"
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# functions -- evaluation\n",
    "######################################################################\n",
    "\n",
    "def performance(y_true, y_pred, metric=\"accuracy\"):\n",
    "    \"\"\"\n",
    "    Calculates the performance metric based on the agreement between the\n",
    "    true labels and the predicted labels.\n",
    "\n",
    "    Parameters\n",
    "    --------------------\n",
    "        y_true -- numpy array of shape (n,), known labels\n",
    "        y_pred -- numpy array of shape (n,), (continuous-valued) predictions\n",
    "        metric -- string, option used to select the performance measure\n",
    "                  options: 'accuracy', 'f1-score', 'auroc', 'precision',\n",
    "                           'sensitivity', 'specificity'\n",
    "\n",
    "    Returns\n",
    "    --------------------\n",
    "        score  -- float, performance score\n",
    "    \"\"\"\n",
    "    # map continuous-valued predictions to binary labels\n",
    "    y_label = np.sign(y_pred)\n",
    "    y_label[y_label==0] = 1\n",
    "\n",
    "    ### ========== TODO : START ========== ###\n",
    "    # part 1a: compute classifier performance\n",
    "    perf = None\n",
    "    if metric==\"accuracy\":\n",
    "        perf = metrics.accuracy_score(y_true=y_true, y_pred=y_label)\n",
    "    if metric==\"f1-score\":\n",
    "        perf = metrics.f1_score(y_true=y_true, y_pred=y_label)\n",
    "    if metric==\"auroc\":\n",
    "        perf = metrics.roc_auc_score(y_true=y_true, y_score=y_pred)\n",
    "    if metric==\"precision\":\n",
    "        perf = metrics.precision_score(y_true=y_true, y_pred=y_label)\n",
    "    if metric==\"sensitivity\":\n",
    "        perf = metrics.recall_score(y_true=y_true, y_pred=y_label)\n",
    "    if metric==\"specificity\":\n",
    "        tn, fp, fn, tp = metrics.confusion_matrix(y_true=y_true, y_pred=y_label).ravel()\n",
    "        perf = tn /(tn + fp)\n",
    "    return perf\n",
    "    ### ========== TODO : END ========== ###\n",
    "\n",
    "\n",
    "def cv_performance(clf, X, y, kf, metric=\"accuracy\"):\n",
    "    \"\"\"\n",
    "    Splits the data, X and y, into k-folds and runs k-fold cross-validation.\n",
    "    Trains classifier on k-1 folds and tests on the remaining fold.\n",
    "    Calculates the k-fold cross-validation performance metric for classifier\n",
    "    by averaging the performance across folds.\n",
    "\n",
    "    Parameters\n",
    "    --------------------\n",
    "        clf    -- classifier (instance of LinearSVC)\n",
    "        X      -- numpy array of shape (n,d), feature vectors\n",
    "                    n = number of examples\n",
    "                    d = number of features\n",
    "        y      -- numpy array of shape (n,), binary labels {1,-1}\n",
    "        kf     -- model_selection.StratifiedKFold\n",
    "        metric -- string, option used to select performance measure\n",
    "\n",
    "    Returns\n",
    "    --------------------\n",
    "        score   -- float, average cross-validation performance across k folds\n",
    "    \"\"\"\n",
    "\n",
    "    ### ========== TODO : START ========== ###\n",
    "    # part 1b: compute average cross-validation performance\n",
    "    folds = kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "    p = 0\n",
    "    for i, (train, test) in enumerate( kf.split(X,y)):\n",
    "            clf.fit(X[train], y[train])\n",
    "            p += performance(y[test], clf.decision_function(X[test]), metric=metric)\n",
    "            \n",
    "    return p / folds\n",
    "    ### ========== TODO : END ========== ###\n",
    "\n",
    "\n",
    "def select_param_linear(X, y, kf, metric=\"accuracy\"):\n",
    "    \"\"\"\n",
    "    Sweeps different settings for the hyperparameter of a linear SVM,\n",
    "    calculating the k-fold CV performance for each setting, then selecting the\n",
    "    hyperparameter that 'maximize' the average k-fold CV performance.\n",
    "\n",
    "    Parameters\n",
    "    --------------------\n",
    "        X      -- numpy array of shape (n,d), feature vectors\n",
    "                    n = number of examples\n",
    "                    d = number of features\n",
    "        y      -- numpy array of shape (n,), binary labels {1,-1}\n",
    "        kf     -- model_selection.StratifiedKFold\n",
    "        metric -- string, option used to select performance measure\n",
    "\n",
    "    Returns\n",
    "    --------------------\n",
    "        C -- float, optimal parameter value for linear SVM\n",
    "    \"\"\"\n",
    "\n",
    "    print('Linear SVM Hyperparameter Selection based on ' + str(metric) + ':')\n",
    "    C_range = 10.0 ** np.arange(-3, 3)\n",
    "\n",
    "    ### ========== TODO : START ========== ###\n",
    "    # part 1c: select optimal hyperparameter using cross-validation\n",
    "    best = -1\n",
    "    c_val = -1\n",
    "    \n",
    "    for c in C_range:\n",
    "        acc = cv_performance(clf = LinearSVC(loss = 'hinge', random_state= 0, C=c), X=X, y=y, kf = kf, metric=metric)\n",
    "        if acc > best:\n",
    "            best = acc\n",
    "            c_val = c\n",
    "    print(c_val)\n",
    "    return c_val\n",
    "    ### ========== TODO : END ========== ###\n",
    "\n",
    "\n",
    "def performance_test(clf, X, y, metric=\"accuracy\"):\n",
    "    \"\"\"\n",
    "    Estimates the performance of the classifier.\n",
    "\n",
    "    Parameters\n",
    "    --------------------\n",
    "        clf          -- classifier (instance of LinearSVC)\n",
    "                          [already fit to data]\n",
    "        X            -- numpy array of shape (n,d), feature vectors of test set\n",
    "                          n = number of examples\n",
    "                          d = number of features\n",
    "        y            -- numpy array of shape (n,), binary labels {1,-1} of test set\n",
    "        metric       -- string, option used to select performance measure\n",
    "\n",
    "    Returns\n",
    "    --------------------\n",
    "        score        -- float, classifier performance\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    ### ========== TODO : START ========== ###\n",
    "    # part 2b: return performance on test data under a metric.\n",
    "    y_pred = clf.decision_function(X)\n",
    "    score = performance(y_true=y, y_pred=y_pred, metric=metric)\n",
    "    return score\n",
    "    ### ========== TODO : END ========== ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "zMIQRGpYErVF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1811\n",
      "Linear SVM Hyperparameter Selection based on accuracy:\n",
      "1.0\n",
      "Linear SVM Hyperparameter Selection based on f1-score:\n",
      "1.0\n",
      "Linear SVM Hyperparameter Selection based on auroc:\n",
      "1.0\n",
      "Linear SVM Hyperparameter Selection based on precision:\n",
      "10.0\n",
      "Linear SVM Hyperparameter Selection based on sensitivity:\n",
      "0.001\n",
      "Linear SVM Hyperparameter Selection based on specificity:\n",
      "1.0\n",
      "accuracy 0.7428571428571429\n",
      "f1-score 0.47058823529411764\n",
      "auroc 0.7424684159378038\n",
      "precision 0.6363636363636364\n",
      "sensitivity 1.0\n",
      "specificity 0.8979591836734694\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "# main\n",
    "######################################################################\n",
    "\n",
    "def main() :\n",
    "    np.random.seed(1234)\n",
    "\n",
    "    # read the tweets and its labels, change the following two lines to your own path.\n",
    "    ### ========== TODO : START ========== ###\n",
    "    file_path = '/Users/divikchotani/github/ece-m146/HW3-code/data/tweets.txt'\n",
    "    label_path = '/Users/divikchotani/github/ece-m146/HW3-code/data/labels.txt'\n",
    "    ### ========== TODO : END ========== ###\n",
    "    dictionary = extract_dictionary(file_path)\n",
    "    print(len(dictionary))\n",
    "    X = extract_feature_vectors(file_path, dictionary)\n",
    "    y = read_vector_file(label_path)\n",
    "    # split data into training (training + cross-validation) and testing set\n",
    "    X_train, X_test = X[:560], X[560:]\n",
    "    y_train, y_test = y[:560], y[560:]\n",
    "\n",
    "    metric_list = [\"accuracy\", \"f1-score\", \"auroc\", \"precision\", \"sensitivity\", \"specificity\"]\n",
    "\n",
    "    ### ========== TODO : START ========== ###\n",
    "    # part 1b: create stratified folds (5-fold CV)\n",
    "    kf = StratifiedKFold(n_splits=5)\n",
    "    \n",
    "    # part 1c: for each metric, select optimal hyperparameter for linear SVM using CV\n",
    "    cs = []\n",
    "    for metric in metric_list:\n",
    "        cs.append( select_param_linear(X=X_train, y=y_train, kf=kf, metric=metric))\n",
    "    # part 2a: train linear SVMs with selected hyperparameters\n",
    "    clfs = []\n",
    "    for i in range(6):\n",
    "        t = LinearSVC(loss = 'hinge', random_state= 0, C=cs[i]).fit(X = X_train, y = y_train)\n",
    "        clfs.append(t)\n",
    "    # part 2b: test the performance of your classifiers.\n",
    "    for i, clf in enumerate(clfs):\n",
    "        print(metric_list[i], performance_test(clf=clf, X = X_test, y=y_test, metric= metric_list[i]))\n",
    "    ### ========== TODO : END ========== ###\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\" :\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_W-_mjX0JMes"
   },
   "source": [
    "# Problem 4: Boosting vs. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "0uzCdPTkOQSY"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "DVxef2sxOmVI"
   },
   "outputs": [],
   "source": [
    "class Data :\n",
    "    \n",
    "    def __init__(self) :\n",
    "        \"\"\"\n",
    "        Data class.\n",
    "        \n",
    "        Attributes\n",
    "        --------------------\n",
    "            X -- numpy array of shape (n,d), features\n",
    "            y -- numpy array of shape (n,), targets\n",
    "        \"\"\"\n",
    "                \n",
    "        # n = number of examples, d = dimensionality\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        \n",
    "        self.Xnames = None\n",
    "        self.yname = None\n",
    "    \n",
    "    def load(self, filename, header=0, predict_col=-1) :\n",
    "        \"\"\"Load csv file into X array of features and y array of labels.\"\"\"\n",
    "        \n",
    "        # determine filename\n",
    "        f = filename\n",
    "        \n",
    "        # load data\n",
    "        with open(f, 'r') as fid :\n",
    "            data = np.loadtxt(fid, delimiter=\",\", skiprows=header)\n",
    "        \n",
    "        # separate features and labels\n",
    "        if predict_col is None :\n",
    "            self.X = data[:,:]\n",
    "            self.y = None\n",
    "        else :\n",
    "            if data.ndim > 1 :\n",
    "                self.X = np.delete(data, predict_col, axis=1)\n",
    "                self.y = data[:,predict_col]\n",
    "            else :\n",
    "                self.X = None\n",
    "                self.y = data[:]\n",
    "        \n",
    "        # load feature and label names\n",
    "        if header != 0:\n",
    "            with open(f, 'r') as fid :\n",
    "                header = fid.readline().rstrip().split(\",\")\n",
    "                \n",
    "            if predict_col is None :\n",
    "                self.Xnames = header[:]\n",
    "                self.yname = None\n",
    "            else :\n",
    "                if len(header) > 1 :\n",
    "                    self.Xnames = np.delete(header, predict_col)\n",
    "                    self.yname = header[predict_col]\n",
    "                else :\n",
    "                    self.Xnames = None\n",
    "                    self.yname = header[0]\n",
    "        else:\n",
    "            self.Xnames = None\n",
    "            self.yname = None\n",
    "\n",
    "\n",
    "# helper functions\n",
    "def load_data(filename, header=0, predict_col=-1) :\n",
    "    \"\"\"Load csv file into Data class.\"\"\"\n",
    "    data = Data()\n",
    "    data.load(filename, header=header, predict_col=predict_col)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "_Zcf4WVqJSpe"
   },
   "outputs": [],
   "source": [
    "# Change the path to your own data directory\n",
    "### ========== TODO : START ========== ###\n",
    "titanic = load_data(\"/Users/divikchotani/github/ece-m146/HW3-code/data/titanic_train.csv\", header=1, predict_col=0)\n",
    "### ========== TODO : END ========== ###\n",
    "X = titanic.X; Xnames = titanic.Xnames\n",
    "y = titanic.y; yname = titanic.yname\n",
    "n,d = X.shape  # n = number of examples, d =  number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "3Ta7XHRWQGNo"
   },
   "outputs": [],
   "source": [
    "def error(clf, X, y, ntrials=100, test_size=0.2) :\n",
    "    \"\"\"\n",
    "    Computes the classifier error over a random split of the data,\n",
    "    averaged over ntrials runs.\n",
    "\n",
    "    Parameters\n",
    "    --------------------\n",
    "        clf         -- classifier\n",
    "        X           -- numpy array of shape (n,d), features values\n",
    "        y           -- numpy array of shape (n,), target classes\n",
    "        ntrials     -- integer, number of trials\n",
    "        test_size   -- proportion of data used for evaluation\n",
    "\n",
    "    Returns\n",
    "    --------------------\n",
    "        train_error -- float, training error\n",
    "        test_error  -- float, test error\n",
    "    \"\"\"\n",
    "\n",
    "    train_error = 0\n",
    "    test_error = 0\n",
    "\n",
    "    train_scores = [] \n",
    "    test_scores = []\n",
    "    for i in range(ntrials):\n",
    "        xtrain, xtest, ytrain, ytest = train_test_split (X,y, test_size = test_size, random_state = i)\n",
    "        clf.fit (xtrain, ytrain)\n",
    "\n",
    "        ypred = clf.predict (xtrain)\n",
    "        err = 1 - metrics.accuracy_score (ytrain, ypred, normalize = True)\n",
    "        train_scores.append (err)\n",
    "\n",
    "        ypred = clf.predict (xtest)\n",
    "        err = 1 - metrics.accuracy_score (ytest, ypred, normalize = True)\n",
    "        test_scores.append (err)\n",
    "\n",
    "    train_error =  np.mean (train_scores)\n",
    "    test_error = np.mean (test_scores)\n",
    "    return train_error, test_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W8-U3un5PjGq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying using Decision Tree...\n"
     ]
    },
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'random_state' parameter of DecisionTreeClassifier must be an int in the range [0, 4294967295], an instance of 'numpy.random.mtrand.RandomState' or None. Got '0' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidParameterError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mClassifying using Decision Tree...\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m dtclf = DecisionTreeClassifier(criterion=\u001b[33m'\u001b[39m\u001b[33mentropy\u001b[39m\u001b[33m'\u001b[39m, random_state=\u001b[33m'\u001b[39m\u001b[33m0\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m### ========== TODO : END ========== ###\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36merror\u001b[39m\u001b[34m(clf, X, y, ntrials, test_size)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ntrials):\n\u001b[32m     26\u001b[39m     xtrain, xtest, ytrain, ytest = train_test_split (X,y, test_size = test_size, random_state = i)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[43mclf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mxtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m     ypred = clf.predict (xtrain)\n\u001b[32m     30\u001b[39m     err = \u001b[32m1\u001b[39m - metrics.accuracy_score (ytrain, ypred, normalize = \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.4/envs/ece-m146-env/lib/python3.11/site-packages/sklearn/base.py:1382\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1377\u001b[39m partial_fit_and_fitted = (\n\u001b[32m   1378\u001b[39m     fit_method.\u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33mpartial_fit\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m _is_fitted(estimator)\n\u001b[32m   1379\u001b[39m )\n\u001b[32m   1381\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_skip_validation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[32m-> \u001b[39m\u001b[32m1382\u001b[39m     \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_validate_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m   1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.4/envs/ece-m146-env/lib/python3.11/site-packages/sklearn/base.py:436\u001b[39m, in \u001b[36mBaseEstimator._validate_params\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    429\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[32m    430\u001b[39m \n\u001b[32m    431\u001b[39m \u001b[33;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    434\u001b[39m \u001b[33;03m    accepted constraints.\u001b[39;00m\n\u001b[32m    435\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m436\u001b[39m     \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parameter_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.4/envs/ece-m146-env/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:98\u001b[39m, in \u001b[36mvalidate_parameter_constraints\u001b[39m\u001b[34m(parameter_constraints, params, caller_name)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     93\u001b[39m     constraints_str = (\n\u001b[32m     94\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:-\u001b[32m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m or\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[-\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     96\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[32m     99\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    101\u001b[39m )\n",
      "\u001b[31mInvalidParameterError\u001b[39m: The 'random_state' parameter of DecisionTreeClassifier must be an int in the range [0, 4294967295], an instance of 'numpy.random.mtrand.RandomState' or None. Got '0' instead."
     ]
    }
   ],
   "source": [
    "### ========== TODO : START ========== ###\n",
    "# Part 4(a): Implement the decision tree classifier and report the training error.\n",
    "print('Classifying using Decision Tree...')\n",
    "dtclf = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "print(error(dtclf, X=X, y=y))\n",
    "### ========== TODO : END ========== ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_x_PevK8Q4dx"
   },
   "outputs": [],
   "source": [
    "### ========== TODO : START ========== ###\n",
    "# Part 4(b): Implement the random forest classifier and adjust the number of samples used in bootstrap sampling.\n",
    "print('Classifying using Random Forest...')\n",
    "### ========== TODO : END ========== ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZFUyPTPwT53v"
   },
   "outputs": [],
   "source": [
    "### ========== TODO : START ========== ###\n",
    "# Part 4(c): Implement the random forest classifier and adjust the number of features for each decision tree.\n",
    "print('Classifying using Random Forest...')\n",
    "### ========== TODO : END ========== ###"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ece-m146-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
